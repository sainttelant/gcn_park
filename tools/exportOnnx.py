import torch
import onnx
import numpy as np
from PIL import Image
from torchvision import transforms
import pprint
from psdet.utils.config import get_config
from psdet.utils.common import get_logger
from psdet.models.builder import build_model
from pathlib import Path
import onnxruntime 
from torchsummary import summary

import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit

def export_model_to_onnx(model, cfg, device_id=0):
    # è®¾ç½®ä½¿ç”¨çš„è®¾å¤‡
    device = torch.device(f'cuda:{device_id}')
    
    # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡å¹¶è®¾ä¸ºè¯„ä¼°æ¨¡å¼
    model.to(device)
    model.eval()

    # æ¸…ç†ç¼“å­˜
    torch.cuda.empty_cache()

    # 1. å‡†å¤‡çœŸå®å›¾åƒè¾“å…¥
    #image_path = cfg.test_image  # å‡è®¾é…ç½®ä¸­æœ‰æµ‹è¯•å›¾åƒè·¯å¾„
    image_dir = Path(cfg.data_root) / 'testing' / 'indoor-parking lot'
    image = Image.open(image_dir/"001.jpg").convert("RGB")
    
    # åˆ›å»ºä¸æ¨¡å‹é¢„æœŸä¸€è‡´çš„é¢„å¤„ç†ç®¡é“
    preprocess = transforms.Compose([
        transforms.Resize((cfg.image_size[0], cfg.image_size[1])),  # ä½¿ç”¨é…ç½®ä¸­çš„å›¾åƒå°ºå¯¸
        transforms.ToTensor(),          # è½¬æ¢ä¸ºTensor
    ])
    
    # åº”ç”¨é¢„å¤„ç†
    image_tensor = preprocess(image).unsqueeze(0).to(device)  # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
    
    # 2. åˆ›å»ºè¾“å…¥å­—å…¸
    input_dict = {'image': image_tensor}
    
    # å®šä¹‰ä¿å­˜ ONNX æ¨¡å‹çš„è·¯å¾„
    onnx_model_path = cfg.save_onnx_dir
    simplified_path = cfg.simplified_path
    # åˆ›å»ºä¸€ä¸ªå¥å£®çš„æ¨¡å‹åŒ…è£…å™¨
    class ModelWrapper(torch.nn.Module):
        def __init__(self, model):
            super().__init__()
            self.model = model
            
        def forward(self, image):
            # åˆ›å»ºè¾“å…¥å­—å…¸
            input_dict = {'image': image}
            
            # è°ƒç”¨æ¨¡å‹
            data_dict = self.model(input_dict)
            
            # æå–æ¨¡å‹è¾“å‡º
            points_pred = data_dict['points_pred']
            
            # è·å–æè¿°ç¬¦å›¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if 'descriptor_map' in data_dict:
                descriptor_map = data_dict['descriptor_map']
            else:
                # å¯¹äº DirectionalPointDetectorï¼Œæè¿°ç¬¦å›¾å¯èƒ½ä¸å¯ç”¨
                descriptor_map = torch.zeros(
                    image.size(0), 
                    cfg.model['descriptor_dim'] if hasattr(cfg, 'descriptor_dim') else 256,
                    image.size(2) // (cfg.model['depth_factor'] if hasattr(cfg, 'depth_factor') else 8),
                    image.size(3) // (cfg.model['depth_factor'] if hasattr(cfg, 'depth_factor') else 8)
                ).to(image.device)
            
            return points_pred, descriptor_map
    
    # åŒ…è£…æ¨¡å‹å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
    wrapped_model = ModelWrapper(model).to(device)
    wrapped_model.eval()

    # åœ¨å¯¼å‡ºå‰æµ‹è¯•ä¸€æ¬¡å‰å‘ä¼ æ’­
    with torch.no_grad():
        points_pred, descriptor_map = wrapped_model(image_tensor)
        print("è¾“å‡ºç»“æ„:")
        # å®‰å…¨åœ°æ‰“å° points_pred çš„ä¿¡æ¯
        if isinstance(points_pred, torch.Tensor):
            print(f"points_pred: ç±»å‹=å¼ é‡, å½¢çŠ¶={points_pred.shape}")
        elif isinstance(points_pred, (list, tuple)):
            print(f"points_pred: ç±»å‹={type(points_pred)}, é•¿åº¦={len(points_pred)}")
            # æ‰“å°åˆ—è¡¨ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ çš„ç±»å‹ï¼ˆå¦‚æœæœ‰ï¼‰
            if len(points_pred) > 0:
                first_item = points_pred[0]
                print(f"  ç¬¬ä¸€ä¸ªå…ƒç´ çš„ç±»å‹: {type(first_item)}")
                if isinstance(first_item[0], tuple):
                    print(f"  ç¬¬ä¸€ä¸ªå…ƒç»„æœ‰ {len(first_item)} ä¸ªå…ƒç´ ")
                    if len(first_item) > 0:
                        print(f"    ç¬¬ä¸€ä¸ªå…ƒç´ çš„ç½®ä¿¡åº¦: {first_item[0]}")
                        if isinstance(first_item[1], np.ndarray):
                            print(f"    ä½ç½®æ•°ç»„çš„å½¢çŠ¶: {first_item[1].shape}")
        else:
            print(f"points_pred: ç±»å‹={type(points_pred)}")
        
        # å®‰å…¨åœ°æ‰“å° descriptor_map çš„ä¿¡æ¯
        if descriptor_map is not None and isinstance(descriptor_map, torch.Tensor):
            print(f"descriptor_map: ç±»å‹=å¼ é‡, å½¢çŠ¶={descriptor_map.shape}")
        else:
            print(f"descriptor_map: {type(descriptor_map)}")
                    
    # å¯¼å‡ºæ¨¡å‹åˆ° ONNX æ ¼å¼
    torch.onnx.export(
        wrapped_model, 
        image_tensor,
        onnx_model_path/'model.onnx',
        export_params=True,
        opset_version=14,  # ä½¿ç”¨æ›´æ–°çš„ opset ç‰ˆæœ¬
        do_constant_folding=True,
        input_names=['image'],
        output_names=['points_pred', 'descriptor_map'],
        dynamic_axes={
            'image': {0: 'batch_size', 2: 'height', 3: 'width'},
            'points_pred': {0: 'batch_size'},
            'descriptor_map': {0: 'batch_size'}
        }
    )
    print(f"æ¨¡å‹å·²è½¬æ¢ä¸º ONNX å¹¶ä¿å­˜åˆ° {onnx_model_path}")

    # éªŒè¯ ONNX æ¨¡å‹
    onnx_model = onnx.load(onnx_model_path/"model.onnx")
  
    for input in onnx_model.graph.input:
        print(f"Input: {input.name}, Shape: {[dim.dim_value for dim in input.type.tensor_type.shape.dim]}")
        print("ONNX æ¨¡å‹éªŒè¯é€šè¿‡")

    # å¯é€‰ï¼šä¼˜åŒ– ONNX æ¨¡å‹
     # å°è¯•ç®€åŒ–æ¨¡å‹
    try:
        from onnxsim import simplify
        simplified_model, check = simplify(onnx_model)
        onnx.save(simplified_model, simplified_path/"model_simplified.onnx")
        print(f"ONNXæ¨¡å‹ç®€åŒ–å®Œæˆï¼Œä¿å­˜åˆ°: {simplified_path}")
    except ImportError:
        print("è­¦å‘Š: onnx-simplifier æœªå®‰è£…ï¼Œè·³è¿‡æ¨¡å‹ç®€åŒ–æ­¥éª¤")
    except Exception as e:
        print(f"æ¨¡å‹ç®€åŒ–å¤±è´¥: {e}")
    
   
    
    # éªŒè¯ ONNX æ¨¡å‹    
    validation_result = validate_onnx_model(wrapped_model, image_tensor, onnx_model_path)
    if validation_result:
        print("\n[ğŸ‰] ONNXæ¨¡å‹éªŒè¯æˆåŠŸï¼ä¸åŸæ¨¡å‹å®Œå…¨ä¸€è‡´")
    else:
        print("\n[âš ï¸] è­¦å‘Šï¼šONNXæ¨¡å‹è¾“å‡ºä¸åŸå§‹æ¨¡å‹å­˜åœ¨å·®å¼‚")
    
    # æ–°å¢TensorRTéªŒè¯
    if validation_result: 
        trt_result = validate_tensorrt_model(
             onnx_model_path/"model_simplified.onnx",image_tensor
        )
        print(f"\n[ğŸ”] TensorRTéªŒè¯ç»“æœ: {'é€šè¿‡' if trt_result else 'å¤±è´¥'}")
   
def validate_onnx_model(wrapped_model, image_tensor, onnx_model_path):
    # 1. åŠ è½½ONNXæ¨¡å‹å¹¶éªŒè¯åŸºç¡€ç»“æ„
    onnx_model = onnx.load(onnx_model_path/"model_simplified.onnx")
    try:
        onnx.checker.check_model(onnx_model)  # æ£€æŸ¥æ¨¡å‹æ˜¯å¦ç¬¦åˆONNXæ ‡å‡†
        print("[âœ…] ONNXæ¨¡å‹åŸºç¡€ç»“æ„éªŒè¯é€šè¿‡")
    except onnx.checker.ValidationError as e:
        print(f"[âŒ] ONNXæ¨¡å‹ç»“æ„å¼‚å¸¸: {e}")
        return False

    # 2. å‡†å¤‡ONNX Runtimeæ¨ç†ä¼šè¯
    ort_session = onnxruntime.InferenceSession(
        str(onnx_model_path/"model_simplified.onnx"),
        providers=['CUDAExecutionProvider'] if torch.cuda.is_available() else ['CPUExecutionProvider']
    )
    
    # 3. è·å–è¾“å…¥è¾“å‡ºåç§°
    input_name = ort_session.get_inputs()[0].name
    output_names = [out.name for out in ort_session.get_outputs()]
    
    # 4. è¿è¡ŒPyTorchåŸå§‹æ¨¡å‹æ¨ç†
    with torch.no_grad():
        torch_points, torch_desc = wrapped_model(image_tensor)
        
        print("PyTorch pointsæ€»å’Œ:", torch_points.sum().item())
        print("PyTorch pointsç»Ÿè®¡: æ€»å’Œ={:.4f}, æœ€å¤§={:.4f}, æœ€å°={:.4f}".format(
            torch_points.sum().item(),
            torch_points.max().item(),
            torch_points.min().item()
        ))
        # ç¡®ä¿è¾“å‡ºä¸ºå¼ é‡ä»¥ä¾¿æ¯”è¾ƒ
        if not isinstance(torch_points, torch.Tensor):
            torch_points = torch.tensor(torch_points).to(image_tensor.device)
    
    # 5. è¿è¡ŒONNXæ¨¡å‹æ¨ç†
    ort_inputs = {input_name: image_tensor.cpu().numpy()}
    ort_outs = ort_session.run(output_names, ort_inputs)
    onnx_points = torch.from_numpy(ort_outs[0]).to(image_tensor.device)
    onnx_desc = torch.from_numpy(ort_outs[1]).to(image_tensor.device)

    # 6. æ•°å€¼ä¸€è‡´æ€§éªŒè¯ï¼ˆå…³é”®æ­¥éª¤ï¼‰
    passed = True
    # éªŒè¯å…³é”®ç‚¹è¾“å‡º
    points_diff = torch.abs(torch_points - onnx_points)
    max_diff = points_diff.max().item()
    mean_diff = points_diff.mean().item()
    print(f"å…³é”®ç‚¹è¾“å‡ºå·®å¼‚: æœ€å¤§={max_diff:.6f}, å¹³å‡={mean_diff:.6f}")
    if mean_diff > 1e-2:  # è®¾ç½®åˆç†é˜ˆå€¼
        print("[âŒ] å…³é”®ç‚¹è¾“å‡ºå·®å¼‚è¿‡å¤§!")
        passed = False
    
    # éªŒè¯æè¿°ç¬¦è¾“å‡º
    desc_diff = torch.abs(torch_desc - onnx_desc)
    max_desc_diff = desc_diff.max().item()
    mean_desc_diff = desc_diff.mean().item()
    print(f"æè¿°ç¬¦è¾“å‡ºå·®å¼‚: æœ€å¤§={max_desc_diff:.6f}, å¹³å‡={mean_desc_diff:.6f}")
    if mean_desc_diff > 1e-2:
        print("[âŒ] æè¿°ç¬¦è¾“å‡ºå·®å¼‚è¿‡å¤§!")
        passed = False
    
    # 7. åŠ¨æ€å½¢çŠ¶éªŒè¯ï¼ˆå¯é€‰ï¼‰
    if cfg.validate_dynamic_shape:
        print("\n[ğŸ§ª] åŠ¨æ€å½¢çŠ¶éªŒè¯...")
        try:
            # åˆ›å»ºä¸åŒæ‰¹æ¬¡çš„è¾“å…¥
            batch2_input = torch.cat([image_tensor, image_tensor], dim=0)
            ort_inputs_batch2 = {input_name: batch2_input.cpu().numpy()}
            ort_outs_batch2 = ort_session.run(output_names, ort_inputs_batch2)
            print(f"[âœ…] åŠ¨æ€æ‰¹æ¬¡éªŒè¯é€šè¿‡ (batch=2)")
        except Exception as e:
            print(f"[âŒ] åŠ¨æ€å½¢çŠ¶éªŒè¯å¤±è´¥: {str(e)}")
            passed = False
    
    return passed    

import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
import numpy as np
import os

def validate_tensorrt_model(onnx_model_path: str, input_tensor: np.ndarray) -> None:
    """éªŒè¯TensorRTå¼•æ“çš„æ¨ç†æµç¨‹ï¼ˆå«åŠ¨æ€è¾“å…¥æ”¯æŒï¼‰
    
    Args:
        onnx_model_path: ONNXæ¨¡å‹è·¯å¾„
        input_tensor: è¾“å…¥æ•°æ®ï¼ˆnumpyæ•°ç»„ï¼‰
    """
    def preprocess_input(input_tensor: np.ndarray) -> np.ndarray:
        if isinstance(input_tensor, torch.Tensor):
            input_tensor = input_tensor.cpu().detach().numpy()
        return np.ascontiguousarray(input_tensor.astype(np.float32))
    
    input_data = preprocess_input(input_tensor)  
    
    logger = trt.Logger(trt.Logger.WARNING)  # å¯ç”¨è¯¦ç»†æ—¥å¿—ä¾¿äºè°ƒè¯•
    buffers = [None]*3
    
    try:
        # === 1. æ„å»ºTensorRTå¼•æ“ ===
        builder = trt.Builder(logger)
        network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
        parser = trt.OnnxParser(network, logger)
        
        # è§£æONNXæ¨¡å‹
        with open(onnx_model_path, "rb") as f:
            if not parser.parse(f.read()):
                for error_idx in range(parser.num_errors):
                    print(f"ONNXè§£æé”™è¯¯: {parser.get_error(error_idx)}")
                return

        # === 2. åŠ¨æ€è¾“å…¥é…ç½®ï¼ˆå…³é”®ï¼‰ ===
        config = builder.create_builder_config()
        config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)  # 1GBæ˜¾å­˜[2](@ref)
        
        profile = builder.create_optimization_profile()
        input_name = network.get_input(0).name
        actual_shape = input_tensor.shape  # å½“å‰è¾“å…¥çš„å®é™…å½¢çŠ¶
        
        # è®¾ç½®åŠ¨æ€èŒƒå›´ï¼ˆå›ºå®šbatchæ—¶min=opt=maxï¼‰
        """ profile.set_shape(input_name, 
                         min=actual_shape, 
                         opt=actual_shape, 
                         max=actual_shape) """
        profile.set_shape(input_name, 
                         min=(1,3,256,256), 
                         opt=(1,3,512,512), 
                         max=(1,3,1024,1024))
        config.add_optimization_profile(profile)
        
        # æ„å»ºåºåˆ—åŒ–å¼•æ“ï¼ˆæ–°ç‰ˆAPIï¼‰[3](@ref)
        serialized_engine = builder.build_serialized_network(network, config)
        if serialized_engine is None:
            print("å¼•æ“æ„å»ºå¤±è´¥ï¼è¯¦ç»†æ—¥å¿—ï¼š")
            for i in range(logger.num_errors):
                print(logger.get_error(i))
            return
        
        runtime = trt.Runtime(logger)
        engine = runtime.deserialize_cuda_engine(serialized_engine)
        
        # === 3. å¤„ç†è¾“å‡ºå½¢çŠ¶ï¼ˆä¿®å¤è´Ÿç»´åº¦ï¼‰ ===
        def sanitize_shape(shape: tuple) -> list:
            """å°†è´Ÿç»´åº¦æ›¿æ¢ä¸ºå½“å‰batch size"""
            return [dim if dim > 0 else actual_shape[0] for dim in shape]
        
        output_shapes = [
            sanitize_shape(engine.get_tensor_shape("points_pred")),  # è¾“å‡ºåç§°éœ€åŒ¹é…ONNX
            sanitize_shape(engine.get_tensor_shape("descriptor_map"))
        ]
        # éªŒè¯å½¢çŠ¶æœ‰æ•ˆæ€§
        assert all(dim > 0 for shape in output_shapes for dim in shape), "è¾“å‡ºå«éæ³•è´Ÿç»´åº¦ï¼"
        
        # === 4. æ˜¾å­˜åˆ†é…ï¼ˆç±»å‹å®‰å…¨ï¼‰ ===
        # è¾“å…¥æ˜¾å­˜
        input_nbytes = input_data.nbytes
        buffers[0] = cuda.mem_alloc(input_nbytes)
        
        buffers.append(cuda.mem_alloc(input_nbytes))
        
        # è¾“å‡ºæ˜¾å­˜ï¼ˆæ˜¾å¼è½¬æ¢numpy.int64ï¼‰
        output_buffers = []
        for shape in output_shapes:
            num_elements = int(np.prod(shape))  # ç¡®ä¿è½¬ä¸ºPython int
            size_bytes = num_elements * 4  # float32=4å­—èŠ‚
            buf = cuda.mem_alloc(size_bytes)
            buffers.append(buf)
            output_buffers.append(buf)
        
        # === 5. æ‰§è¡Œæ¨ç† ===
        context = engine.create_execution_context()
        context.set_binding_shape(0, actual_shape)  # ç»‘å®šåŠ¨æ€è¾“å…¥å½¢çŠ¶[3](@ref)
        
        # æ•°æ®ä¼ è¾“: Host -> Device
        cuda.memcpy_htod(buffers[0], input_data.tobytes())
        # æ‰§è¡Œæ¨ç†
        bindings = [int(b) for b in buffers if b is not None]
        context.execute_v2(bindings=bindings)
        # æ•°æ®ä¼ è¾“: Device -> Host
        host_outputs = []
        for buf in output_buffers:
            host_out = np.empty(output_shapes[0], dtype=np.float32)  # ç¤ºä¾‹å–ç¬¬ä¸€ä¸ªè¾“å‡º
            cuda.memcpy_dtoh(host_out, buf)
            host_outputs.append(host_out)
        
        print(f"æ¨ç†æˆåŠŸï¼è¾“å‡ºå½¢çŠ¶: {[out.shape for out in host_outputs]}")
        output_names = ["points_pred", "descriptor_map"]
        output_indices = [engine.get_binding_index(name) for name in output_names]
        assert all(idx != -1 for idx in output_indices), "è¾“å‡ºåç§°æœªåŒ¹é…ï¼"
        
    except Exception as e:
        print(f"éªŒè¯å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        
    finally:
        # === 6. æ˜¾å­˜é‡Šæ”¾ï¼ˆé˜²æ­¢æ³„æ¼ï¼‰ ===
        for buf in buffers:
            if buf:
                buf.free()
        print("æ˜¾å­˜èµ„æºå·²é‡Šæ”¾")
    
if __name__ == '__main__':
    cfg = get_config()
    logger = get_logger(cfg.log_dir, cfg.tag)
    logger.info(pprint.pformat(cfg))
    
    model = build_model(cfg.model)
    logger.info(model)
    model.load_params_from_file(filename=cfg.ckpt, logger=logger, to_cpu=False)

    device = torch.device('cuda:0')
    model.to(device)

    export_model_to_onnx(model, cfg, device_id=0)
    